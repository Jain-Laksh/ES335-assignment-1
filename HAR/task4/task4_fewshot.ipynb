{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\LAKSH_LAYING.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\LAKSH_SITTING.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\LAKSH_STANDING.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\LAKSH_WALKING.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\LAKSH_WALKING_DOWNSTAIRS.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\LAKSH_WALKING_UPSTAIRS.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\RUDRA_LAYING.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\RUDRA_SITTING.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\RUDRA_STANDING.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\RUDRA_WALKING.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\RUDRA_WALKING_DOWNSTAIRS.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\RUDRA_WALKING_UPSTAIRS.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\PARTHIV_LAYING.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\PARTHIV_SITTING.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\PARTHIV_STANDING.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\PARTHIV_WALKING.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\PARTHIV_WALKING_DOWNSTAIRS.csv\n",
      "Checking file: c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\Codes\\ML\\task4\\PARTHIV_WALKING_UPSTAIRS.csv\n",
      "Data merging complete. The combined dataset (first 500 rows) has been created and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define subjects\n",
    "subjects = ['LAKSH', 'RUDRA', 'PARTHIV']\n",
    "\n",
    "# Define activities\n",
    "activities = ['LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS', 'WALKING_UPSTAIRS']\n",
    "\n",
    "# Function to load the first 500 rows of each dataset\n",
    "def load_data(subjects, activities):\n",
    "    data_list = []\n",
    "    for subject in subjects:\n",
    "        for activity in activities:\n",
    "            file_name = f\"{subject}_{activity}.csv\"\n",
    "            file_path = os.path.join(os.getcwd(), file_name)\n",
    "            print(f\"Checking file: {file_path}\")  # Debugging line\n",
    "            if os.path.exists(file_path):\n",
    "                # Read the first 500 rows\n",
    "                df = pd.read_csv(file_path, nrows=500)\n",
    "                df['Activity'] = activity\n",
    "                df['Subject'] = subject\n",
    "                data_list.append(df)\n",
    "            else:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "    return pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Load and process data\n",
    "combined_data_df = load_data(subjects, activities)\n",
    "\n",
    "# Save combined DataFrame to CSV if needed\n",
    "combined_data_df.to_csv('combined_taken_data.csv', index=False)\n",
    "\n",
    "print(\"Data merging complete. The combined dataset (first 500 rows) has been created and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "model_name = os.getenv(\"MODEL_NAME\")\n",
    "\n",
    "groq_models = {\n",
    "    \"llama3-70b\": \"llama3-70b-8192\",\n",
    "    \"mixtral\": \"mixtral-8x7b-32768\",\n",
    "    \"gemma-7b\": \"gemma-7b-it\",\n",
    "    \"llama3.1-70b\": \"llama-3.1-70b-versatile\",\n",
    "    \"llama3-8b\": \"llama3-8b-8192\",\n",
    "    \"llama3.1-8b\": \"llama-3.1-8b-instant\",\n",
    "    \"gemma-9b\": \"gemma2-9b-it\"\n",
    "}\n",
    "\n",
    "llm = ChatGroq(model=groq_models[model_name] , api_key=groq_api_key, temperature=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">TRAINED ON GIVEN DATASET, TESTED ON COLLECTED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYING LAYING\n",
      "1\n",
      "SITTING STANDING\n",
      "STANDING STANDING\n",
      "2\n",
      "WALKING WALKING\n",
      "3\n",
      "WALKING_DOWNSTAIRS WALKING_UPSTAIRS\n",
      "WALKING_UPSTAIRS WALKING\n",
      "LAYING LAYING\n",
      "4\n",
      "SITTING STANDING\n",
      "STANDING STANDING\n",
      "5\n",
      "WALKING WALKING_UPSTAIRS\n",
      "WALKING_DOWNSTAIRS WALKING\n",
      "WALKING_UPSTAIRS WALKING_UPSTAIRS\n",
      "6\n",
      "LAYING LAYING\n",
      "7\n",
      "SITTING STANDING\n",
      "STANDING STANDING\n",
      "8\n",
      "WALKING WALKING\n",
      "9\n",
      "WALKING_DOWNSTAIRS WALKING\n",
      "WALKING_UPSTAIRS WALKING\n",
      "Classification complete. Results have been saved to 'model_predictions.csv'.\n",
      "accuracy 50.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have the test data loaded as a DataFrame\n",
    "test_data_df = pd.read_csv('combined_taken_data.csv')\n",
    "\n",
    "# Placeholder for storing results\n",
    "results = []\n",
    "\n",
    "# Define the activities\n",
    "activities = ['LAYING', 'STANDING', 'WALKING', 'SITTING', 'WALKING UPSTAIRS', 'WALKING DOWNSTAIRS']\n",
    "\n",
    "def sample_data(data, sample_rate=10):\n",
    "    n=500//sample_rate\n",
    "    return data[100:n+100]\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Filter training data for specific subjects\n",
    "train_subjects = [1, 3, 5, 7]\n",
    "train_data_df = pd.read_csv('train_data_combined.csv')\n",
    "train_data_df = train_data_df[train_data_df['Subject'].isin(train_subjects)]\n",
    "\n",
    "# Iterate through each group by subject and activity\n",
    "for (subject, activity), group in test_data_df.groupby(['Subject', 'Activity']):\n",
    "    # Sample data\n",
    "    accx = sample_data(group['gFx'].tolist())\n",
    "    accy = sample_data(group['gFy'].tolist())\n",
    "    accz = sample_data(group['gFz'].tolist())\n",
    "    \n",
    "    # Create prompt for the current group\n",
    "    query_few_shot_Task4 = f\"\"\"\n",
    "    * You are a highly accurate activity classification model.\n",
    "    * Your task is to classify human activities based on the given accelerometer data.\n",
    "    * The accelerometer data is provided as mean acceleration values in the x, y, and z directions.\n",
    "    * You are given data corresponding to six different activities.\n",
    "    * The possible activities to classify are: LAYING, STANDING, WALKING, SITTING, WALKING UPSTAIRS, and WALKING DOWNSTAIRS.\"\"\"\n",
    "\n",
    "    for (train_subject, train_activity), grp in train_data_df.groupby(['Subject', 'Activity']):\n",
    "        query_few_shot_Task4 += \"\"\"Here are some examples of accelerometer data and their corresponding activities:\"\"\"\n",
    "\n",
    "        query_few_shot_Task4 += f\"\"\"\n",
    "        * Activity: {train_activity}\n",
    "          accx = {sample_data(grp['accx'].tolist(), 50)}\n",
    "          accy = {sample_data(grp['accy'].tolist(), 50)}\n",
    "          accz = {sample_data(grp['accz'].tolist(), 50)}\n",
    "        \"\"\"\n",
    "    \n",
    "    query_few_shot_Task4 += f\"\"\"\n",
    "    * Analyze the accelerometer data and provide the most likely activity label for each case.\n",
    "    * PRINT ONLY A WORD WHICH IS THE PREDICTED ACTIVITY AND NOTHING ELSE NO CONTENT NO REASON JUST A PREDICTION\n",
    "\n",
    "    accx = {accx}\n",
    "    accy = {accy}\n",
    "    accz = {accz}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simulate model prediction (replace with actual model prediction code)\n",
    "    result = llm.invoke(query_few_shot_Task4)\n",
    "    \n",
    "    print(activity, str(result).split(\" \")[0][8:].strip(\"'\"))\n",
    "    if (activity.upper() ==str(result).split(\" \")[0][8:].strip(\"'\")):\n",
    "        i+=1\n",
    "        print(i)\n",
    "    results.append({'Subject': subject, 'Activity': activity, 'Prediction': str(result).split(\" \")[0][8:].strip(\"'\")})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV if needed\n",
    "results_df.to_csv('model_predictions_fewshot_4.1.csv', index=False)\n",
    "\n",
    "print(\"Classification complete. Results have been saved to 'model_predictions.csv'.\")\n",
    "\n",
    "print(\"accuracy\",i/18*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCURACY FOR FEW SHOT IS 50% FOR UCI-HAR TRAINED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> FEW SHOT FOR TRAIN AND TEST BOTH ON THE COLLECTED DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYING LAYING\n",
      "1\n",
      "SITTING STANDING\n",
      "STANDING STANDING\n",
      "2\n",
      "WALKING WALKING_UPSTAIRS\n",
      "WALKING_DOWNSTAIRS WALKING_UPSTAIRS\n",
      "WALKING_UPSTAIRS WALKING_UPSTAIRS\n",
      "3\n",
      "LAYING LAYING\n",
      "4\n",
      "SITTING STANDING\n",
      "STANDING STANDING\n",
      "5\n",
      "WALKING WALKING_UPSTAIRS\n",
      "WALKING_DOWNSTAIRS WALKING_UPSTAIRS\n",
      "WALKING_UPSTAIRS WALKING_UPSTAIRS\n",
      "6\n",
      "Classification complete. Results have been saved to 'model_predictions.csv'.\n",
      "accuracy 50.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have the test data loaded as a DataFrame\n",
    "whole_df = pd.read_csv('combined_taken_data.csv')\n",
    "\n",
    "# Placeholder for storing results\n",
    "results = []\n",
    "\n",
    "# Define the activities\n",
    "activities = ['LAYING', 'STANDING', 'WALKING', 'SITTING', 'WALKING UPSTAIRS', 'WALKING DOWNSTAIRS']\n",
    "\n",
    "def sample_data(data, sample_rate=10):\n",
    "    n=500//sample_rate\n",
    "    return data[100:n+100]\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Filter training data for specific subjects\n",
    "\n",
    "train_data_df = whole_df[whole_df[\"Subject\"] == \"LAKSH\"]\n",
    "test_data_df = whole_df[whole_df[\"Subject\"] != \"LAKSH\"]\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through each group by subject and activity\n",
    "for (subject, activity), group in test_data_df.groupby(['Subject', 'Activity']):\n",
    "    # Sample data\n",
    "    accx = sample_data(group['gFx'].tolist())\n",
    "    accy = sample_data(group['gFy'].tolist())\n",
    "    accz = sample_data(group['gFz'].tolist())\n",
    "    \n",
    "    # Create prompt for the current group\n",
    "    query_few_shot_Task4 = f\"\"\"\n",
    "    * You are a highly accurate activity classification model.\n",
    "    * Your task is to classify human activities based on the given accelerometer data.\n",
    "    * The accelerometer data is provided as mean acceleration values in the x, y, and z directions.\n",
    "    * You are given data corresponding to six different activities.\n",
    "    * The possible activities to classify are: LAYING, STANDING, WALKING, SITTING, WALKING UPSTAIRS, and WALKING DOWNSTAIRS.\"\"\"\n",
    "\n",
    "    for (train_subject, train_activity), grp in train_data_df.groupby(['Subject', 'Activity']):\n",
    "        query_few_shot_Task4 += \"\"\"Here are some examples of accelerometer data and their corresponding activities:\"\"\"\n",
    "\n",
    "        query_few_shot_Task4 += f\"\"\"\n",
    "        * Activity: {train_activity}\n",
    "          accx = {sample_data(grp['gFx'].tolist(), 50)}\n",
    "          accy = {sample_data(grp['gFy'].tolist(), 50)}\n",
    "          accz = {sample_data(grp['gFz'].tolist(), 50)}\n",
    "        \"\"\"\n",
    "    \n",
    "    query_few_shot_Task4 += f\"\"\"\n",
    "    * Analyze the accelerometer data and provide the most likely activity label for each case.\n",
    "    * PRINT ONLY A WORD WHICH IS THE PREDICTED ACTIVITY AND NOTHING ELSE NO CONTENT NO REASON JUST A PREDICTION\n",
    "\n",
    "    accx = {accx}\n",
    "    accy = {accy}\n",
    "    accz = {accz}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simulate model prediction (replace with actual model prediction code)\n",
    "    result = llm.invoke(query_few_shot_Task4)\n",
    "    \n",
    "    print(activity, str(result).split(\" \")[0][8:].strip(\"'\"))\n",
    "    if (activity.upper() ==str(result).split(\" \")[0][8:].strip(\"'\")):\n",
    "        i+=1\n",
    "        print(i)\n",
    "    results.append({'Subject': subject, 'Activity': activity, 'Prediction': str(result).split(\" \")[0][8:].strip(\"'\")})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV if needed\n",
    "results_df.to_csv('model_predictions_fewshot_4.2.csv', index=False)\n",
    "\n",
    "print(\"Classification complete. Results have been saved to 'model_predictions.csv'.\")\n",
    "\n",
    "print(\"accuracy\",i/12*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCURACY IS 50% FOR BOTH TEST AND TRAIN ON THE COLLECTED DATA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
